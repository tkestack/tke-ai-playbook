deployments:
- name: mixed 
  image: "ccr.ccs.tencentyun.com/tke-ai-playbook/dynamo:v0.3.0-lws-pr1333"
  imagePullPolicy: IfNotPresent
  debug: false
  replicas: 1
  resources:
    requests:
      nvidia.com/gpu: 8
    limits:
      nvidia.com/gpu: 8
  service:
    enable: true
    port: 8000
  component: "Frontend"
  workspace: /workspace/examples/llm
  graphs: |
    from components.frontend import Frontend
    from components.processor import Processor
    from components.worker import VllmWorker
    from components.prefill_worker import PrefillWorker

    Frontend.link(Processor).link(VllmWorker).link(PrefillWorker)
  configs: |
    Common:
      model: /data/models/Qwen/Qwen3-32B
      block-size: 128
      max-model-len: 16384
      kv-transfer-config: '{"kv_connector":"DynamoNixlConnector"}'
      tensor-parallel-size: 4
      max-num-batched-tokens: 16384

    Frontend:
      served_model_name: Qwen/Qwen3-32B
      endpoint: dynamo.Processor.chat/completions
      port: 8000

    Processor:
      router: round-robin
      common-configs: [model, block-size]

    VllmWorker:
      remote-prefill: true
      conditional-disagg: false
      ServiceArgs:
        workers: 1
        resources:
          gpu: '4'
      common-configs: [model, block-size, max-model-len, kv-transfer-config, tensor-parallel-size]

    PrefillWorker:
      enforce-eager: true
      ServiceArgs:
        workers: 1
        resources:
          gpu: '4'
      common-configs: [model, block-size, max-model-len, kv-transfer-config, tensor-parallel-size, max-num-batched-tokens, enforce-eager]
  additionalConfigs: []

- name: prefillworker
  image: "ccr.ccs.tencentyun.com/tke-ai-playbook/dynamo:v0.3.0-lws-pr1333"
  imagePullPolicy: Always
  debug: false
  replicas: 1
  resources:
    requests:
      nvidia.com/gpu: 8
    limits:
      nvidia.com/gpu: 8
  service:
    enable: false
  component: "PrefillWorker"
  workspace: /workspace/examples/llm
  graphs: |
    from components.prefill_worker import PrefillWorker
  configs: |
    Common:
      model: /data/models/Qwen/Qwen3-32B
      block-size: 128
      max-model-len: 16384
      kv-transfer-config: '{"kv_connector":"DynamoNixlConnector"}'
      tensor-parallel-size: 4
      max-num-batched-tokens: 16384

    PrefillWorker:
      enforce-eager: true
      ServiceArgs:
        workers: 2
        resources:
          gpu: '4'
      common-configs: [model, block-size, max-model-len, kv-transfer-config, tensor-parallel-size, max-num-batched-tokens, enforce-eager]
  additionalConfigs: []

modelVolume:
  hostPath:
    path: /data0

nats:
  enable: true
  config:
    jetstream:
      enabled: true
      fileStore:
        enabled: true
        dir: /data
        pvc:
          enabled: true
          size: 10Gi

etcd:
  enable: true
  replicaCount: 1
  # Explicitly remove authentication
  auth:
    rbac:
      create: false

  readinessProbe:
    enabled: false

  livenessProbe:
    enabled: false

  persistence:
    size: 20Gi
    resources:
    requests:
      cpu: 10
      memory: 20Gi
    limits:
      cpu: 10
      memory: 20Gi
