vllm:
  enable: true
  replicas: 2
  image: "ccr.ccs.tencentyun.com/tke-ai-playbook/vllm-openai:v0.9.0.1"
  cmd: |
    vllm serve /data/models/deepseek-ai/DeepSeek-R1 \
      --served-model-name deepseek-ai/DeepSeek-R1 \
      --block-size 128 \
      --max-model-len 4096 \
      --max-num-batched-tokens 4096 \
      --no-enable-prefix-caching \
      --enable-chunked-prefill \
      --compilation-config '{"cudagraph_capture_sizes": [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256]}' \
      -tp 16 \
      --disable-log-requests \
      --enable-reasoning \
      --reasoning-parser deepseek_r1

dynamo:
  enable: false

modelVolume:
  hostPath:
    path: /data0

configs: "null"

graphs: "null"

nats:
  enable: false

etcd:
  enable: false